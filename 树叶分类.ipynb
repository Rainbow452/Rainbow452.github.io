{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a931944",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "import shutil\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be28d085",
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成训练集\n",
    "f = os.path.join(\"..\", \"data\", \"test.csv\")\n",
    "train_data = pd.read_csv(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79cad003",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_dataset(fpath, tpath = 'data'):  # fpath ：输入数据csv ， tpath ： 目标文件夹（自动创建） \n",
    "                                                                #scale ： 验证集比例\n",
    "    \n",
    "    \n",
    "    data = pd.read_csv(fpath) # csv\n",
    "    os.makedirs(os.path.join(tpath), exist_ok=True)  #创建目标文件夹 默认为 data\n",
    "\n",
    "    if data.shape[1] == 2 :   #训练集\n",
    "        fname = os.path.join(tpath, 'trainset')# 训练集目标位置\n",
    "        os.makedirs(fname, exist_ok=True)\n",
    "        for i in range(data.shape[0]):\n",
    "            os.makedirs(os.path.join(fname, data.iloc[i,1]), exist_ok=True)\n",
    "            shutil.copy(os.path.join(*fpath.split('\\\\')[:-1], data.iloc[i, 0]), os.path.join(fname, data.iloc[i,1]))\n",
    "\n",
    "    elif data.shape[1] == 1: #验证集\n",
    "        fname = os.path.join(tpath, 'predictset')\n",
    "        os.makedirs(fname, exist_ok=True)\n",
    "        for i in range(data.shape[0]):\n",
    "            shutil.copy(os.path.join( *fpath.split('\\\\')[:-1], data.iloc[i, 0]), fname)\n",
    "    else:\n",
    "        assert 'make dataset error!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2959a360",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_dataset(os.path.join('..', 'data', 'test.csv'), 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "36e31f6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] 当文件已存在时，无法创建该文件。: 'train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-86afea7a4657>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mmake_testset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'trainset'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-50-86afea7a4657>\u001b[0m in \u001b[0;36mmake_testset\u001b[1;34m(fpath, tpath, scale)\u001b[0m\n\u001b[0;32m      5\u001b[0m         tpath:目标文件夹'''\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'file exist'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'test'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\pytorch\\lib\\os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n\u001b[0;32m    221\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[1;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] 当文件已存在时，无法创建该文件。: 'train'"
     ]
    }
   ],
   "source": [
    "\n",
    "def make_testset(fpath, tpath, scale=.0): \n",
    "    '''func:将完整训练数据随机按scale 比例分成 train 和 test 文件夹\n",
    "        parmarater:\n",
    "        fpath:完好的训练数据文件夹， \n",
    "        tpath:目标文件夹'''\n",
    "    \n",
    "    os.makedirs(os.path.join(tpath), exist_ok=False), 'file exist'\n",
    "    os.makedirs(os.path.join(tpath, 'train'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(tpath, 'test'), exist_ok=True)\n",
    "    class_name = os.listdir(fpath)\n",
    "#     num_scale = len(list_name)  #总共类别\n",
    "    for class_leaves in class_name:\n",
    "        imgname = os.listdir(os.path.join(*fpath.split('\\\\'), class_leaves))  #每一类数据的文件夹\n",
    "        testdir = os.path.join(tpath, 'test', class_leaves)\n",
    "        traindir = os.path.join(tpath, 'train', class_leaves)\n",
    "        \n",
    "        os.makedirs(testdir, exist_ok=True)\n",
    "        os.makedirs(traindir, exist_ok=True)\n",
    "        for i in range(int(len(imgname) * scale)):\n",
    "            j = random.randint(0, len(imgname) -1)\n",
    "            \n",
    "            shutil.copy(os.path.join( *fpath.split('\\\\'), class_leaves, imgname[j]), testdir)\n",
    "            del imgname[j]\n",
    "        for img in imgname:\n",
    "            shutil.copy(os.path.join( *fpath.split('\\\\'), class_leaves, img), traindir)\n",
    "        \n",
    "        \n",
    "make_testset(os.path.join('data', 'trainset'),'train', scale=0.2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "100f5c29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4c5c1a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#图片处理流水线 resize 224, 转为向量 归一化\n",
    "transform = transforms.Compose([transforms.Resize(224), transforms.ToTensor()])\n",
    "dataset = datasets.ImageFolder(os.path.join('..','dataset'), transform=transform)\n",
    "dataloader = torch.utils.data.DataLoader(dataset,batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "667e6804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(172)\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(dataloader))\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "33dbf916",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('data\\label.txt', 'w') as f:\n",
    "    for i in os.listdir('data/trainset'):\n",
    "        f.writelines(i + '\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "416ed2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#返回labels\n",
    "def getlabel():\n",
    "    with open('data/label.txt', 'r') as f:\n",
    "        label = []\n",
    "        for i in range(100):\n",
    "            label.append(f.readline().replace('\\n', ''))\n",
    "            if not f.readline:\n",
    "                break;\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb6115fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "██████████        \n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
