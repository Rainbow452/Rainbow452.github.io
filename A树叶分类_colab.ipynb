{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6977c7b4",
      "metadata": {
        "id": "6977c7b4"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install git+https://github.com/d2l-ai/d2l-zh@release  # installing d2l\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd8544f3",
      "metadata": {
        "id": "fd8544f3"
      },
      "source": [
        "## 安装kaggle、凭证（$\\color{#FF0000}{记得转入kaggle.json}$）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "97481760",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97481760",
        "outputId": "5267cedd-a456-4034-be12-8385f4807d5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.19.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
            "Collecting kaggle\n",
            "  Using cached kaggle-1.5.12-py3-none-any.whl\n",
            "Installing collected packages: kaggle\n",
            "  Attempting uninstall: kaggle\n",
            "    Found existing installation: kaggle 1.5.12\n",
            "    Uninstalling kaggle-1.5.12:\n",
            "      Successfully uninstalled kaggle-1.5.12\n",
            "Successfully installed kaggle-1.5.12\n",
            "classify-leaves.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ],
      "source": [
        "!pip install matplotlib\n",
        "!pip install -U -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/kaggle.json  /root/.kaggle\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "\n",
        "!pip install --upgrade --force-reinstall --no-deps kaggle\n",
        "!kaggle competitions download -c classify-leaves "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e51f0f9a",
      "metadata": {
        "scrolled": false,
        "id": "e51f0f9a"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "from d2l import torch as d2l\n",
        "from torch.nn import functional as F\n",
        "from torchvision import datasets, transforms\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "import random\n",
        "import matplotlib as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dde342f4",
      "metadata": {
        "id": "dde342f4"
      },
      "source": [
        "##  解压数据"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b90a72ac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b90a72ac",
        "outputId": "6dcedcfc-b4a4-49cf-d062-ae5850495b82"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "\n",
        "\n",
        "def un_zip(file_name):\n",
        "    \"\"\"unzip zip file\"\"\"\n",
        "    base_dir = os.path.dirname(file_name)\n",
        "    zip_file = zipfile.ZipFile(file_name, 'r')\n",
        "    os.makedirs(os.path.join(*file_name.split('.')[:-1])   ,exist_ok=True )\n",
        "    zip_file.extractall(os.path.join(*file_name.split('.')[:-1]) )\n",
        "\n",
        "un_zip('classify-leaves.zip')\n",
        "len(os.listdir('classify-leaves'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a074b000",
      "metadata": {
        "id": "a074b000"
      },
      "source": [
        "## 数据集处理01(训练集csv-->将数据放到指定文件夹)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "1a08d58b",
      "metadata": {
        "id": "1a08d58b"
      },
      "outputs": [],
      "source": [
        "#数据集 处理\n",
        "def make_dataset(fpath, tpath = 'data'):\n",
        "    \n",
        "    \n",
        "    data = pd.read_csv(fpath) # csv\n",
        "    os.makedirs(os.path.join(tpath), exist_ok=True)\n",
        "    for i in range(data.shape[0]):\n",
        "        if data.shape[1] == 2: #训练集\n",
        "            fname = os.path.join(tpath, 'trainset')# 训练集目标位置\n",
        "            os.makedirs(fname, exist_ok=True)\n",
        "            os.makedirs(os.path.join(fname, data.iloc[i,1]), exist_ok=True)\n",
        "            shutil.copy(os.path.join(*fpath.split('/')[:-1], data.iloc[i, 0]), os.path.join(fname, data.iloc[i,1]))\n",
        "            \n",
        "        elif data.shape[1] == 1: #测试集\n",
        "            fname = os.path.join(tpath, 'testset')\n",
        "            os.makedirs(fname, exist_ok=True)\n",
        "            shutil.copy(os.path.join( *fpath.split('/')[:-1], data.iloc[i, 0]), fname)\n",
        "        else:\n",
        "            assert 'make dataset error!'\n",
        "\n",
        "make_dataset(os.path.join('classify-leaves', 'train.csv'), 'data')\n",
        "make_dataset(os.path.join('classify-leaves', 'test.csv'), 'data')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4a691a2",
      "metadata": {
        "id": "a4a691a2"
      },
      "source": [
        "##  数据集处理02(训练集 -->按比例随机将数据放入文件夹)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ad9ff6ff",
      "metadata": {
        "id": "ad9ff6ff"
      },
      "outputs": [],
      "source": [
        "\n",
        "def make_testset(fpath, tpath, scale=.0): \n",
        "    '''func:将完整训练数据随机按scale 比例分成 train 和 test 文件夹\n",
        "        parmarater:\n",
        "        fpath:完好的训练数据文件夹， \n",
        "        tpath:目标文件夹'''\n",
        "\n",
        "    os.makedirs(os.path.join(tpath), exist_ok=True)\n",
        "    os.makedirs(os.path.join(tpath, 'train'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(tpath, 'test'), exist_ok=True)\n",
        "    class_name = os.listdir(fpath)\n",
        "#     num_scale = len(list_name)  #总共类别\n",
        "    for class_leaves in class_name:\n",
        "        imgname = os.listdir(os.path.join(fpath, class_leaves))  #每一类数据的文件夹\n",
        "        testdir = os.path.join(tpath, 'test', class_leaves)\n",
        "        traindir = os.path.join(tpath, 'train', class_leaves)\n",
        "        \n",
        "        os.makedirs(testdir, exist_ok=True)\n",
        "        os.makedirs(traindir, exist_ok=True)\n",
        "        for i in range(int(len(imgname) * scale)):\n",
        "            j = random.randint(0, len(imgname) -1)\n",
        "            \n",
        "            shutil.copy(os.path.join(fpath, class_leaves, imgname[j]), testdir)\n",
        "            del imgname[j]\n",
        "        for img in imgname:\n",
        "            shutil.copy(os.path.join(fpath, class_leaves, img), traindir)\n",
        " \n",
        "        \n",
        "make_testset(os.path.join('data', 'trainset'),'train', scale=0.3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "377f731a",
      "metadata": {
        "id": "377f731a"
      },
      "source": [
        "## resnet-11 模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c9e0c34d",
      "metadata": {
        "id": "c9e0c34d"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Residual(nn.Module):\n",
        "    def __init__(self, input_channels, num_channels,\n",
        "                use_1x1conv=False, strides=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(input_channels, num_channels, \n",
        "                               kernel_size=3, padding=1, stride=strides)\n",
        "        self.conv2 = nn.Conv2d(num_channels, num_channels, \n",
        "                               kernel_size=3, padding=1)\n",
        "        \n",
        "        if use_1x1conv:\n",
        "            self.conv3 = nn.Conv2d(input_channels, num_channels, \n",
        "                                   kernel_size=1, stride=strides)\n",
        "        else:\n",
        "            self.conv3 = None\n",
        "        self.bn1 = nn.BatchNorm2d(num_channels)\n",
        "        self.bn2 = nn.BatchNorm2d(num_channels)\n",
        "        \n",
        "    def forward(self, X):\n",
        "        Y = F.relu(self.bn1(self.conv1(X)))\n",
        "        Y = self.bn2(self.conv2(Y))\n",
        "        if self.conv3:\n",
        "            X = self.conv3(X)\n",
        "        Y += X\n",
        "        return F.relu(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "86a555a1",
      "metadata": {
        "id": "86a555a1"
      },
      "outputs": [],
      "source": [
        "b1 = nn.Sequential(\n",
        "    nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,),\n",
        "    nn.BatchNorm2d(64),nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=3, stride=2, padding =1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "425e358e",
      "metadata": {
        "id": "425e358e"
      },
      "outputs": [],
      "source": [
        "def resnet_block(input_channels, num_channels, num_residuals, \n",
        "                first_block=False):\n",
        "    blk = []\n",
        "    for i in range(num_residuals):\n",
        "        if i == 0 and not first_block:\n",
        "            blk.append(Residual(input_channels, num_channels, \n",
        "                               use_1x1conv=True, strides=2))\n",
        "        else:\n",
        "            blk.append(Residual(num_channels, num_channels))\n",
        "    return blk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "b7b8e651",
      "metadata": {
        "id": "b7b8e651"
      },
      "outputs": [],
      "source": [
        "b2 = nn.Sequential(*resnet_block(64, 64, 2, first_block=True))\n",
        "b3 = nn.Sequential(*resnet_block(64, 128, 2))\n",
        "b4 = nn.Sequential(*resnet_block(128, 256, 2))\n",
        "b5 = nn.Sequential(*resnet_block(256, 512, 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "81b475b9",
      "metadata": {
        "id": "81b475b9"
      },
      "outputs": [],
      "source": [
        "net =nn.Sequential(b1, b2, b3, b4, b5, \n",
        "                  nn.AdaptiveAvgPool2d((1,1)),\n",
        "                  nn.Flatten(), nn.Linear(512, 176))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "303d6b28",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "303d6b28",
        "outputId": "2b385e8e-33d1-4081-84f9-02d6434c35e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential output shape:\t torch.Size([1, 64, 56, 56])\n",
            "Sequential output shape:\t torch.Size([1, 64, 56, 56])\n",
            "Sequential output shape:\t torch.Size([1, 128, 28, 28])\n",
            "Sequential output shape:\t torch.Size([1, 256, 14, 14])\n",
            "Sequential output shape:\t torch.Size([1, 512, 7, 7])\n",
            "AdaptiveAvgPool2d output shape:\t torch.Size([1, 512, 1, 1])\n",
            "Flatten output shape:\t torch.Size([1, 512])\n",
            "Linear output shape:\t torch.Size([1, 176])\n"
          ]
        }
      ],
      "source": [
        "X = torch.rand(size=(1, 3, 224, 224))\n",
        "for layer in net:\n",
        "    X = layer(X)\n",
        "    print(layer.__class__.__name__,'output shape:\\t', X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "8c636e63",
      "metadata": {
        "id": "8c636e63"
      },
      "outputs": [],
      "source": [
        "def train_ch6(net, trian_iter, test_iter, num_epochs, lr, device):\n",
        "    def init_weights(m):\n",
        "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
        "            nn.init.xavier_uniform_(m.weight)\n",
        "    net.apply(init_weights)\n",
        "    print('trianing on', device)\n",
        "    net.to(device)\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "    loss = nn.CrossEntropyLoss()\n",
        "    animator = d2l.Animator(xlabel='epoch', xlim=[1,num_epochs],\n",
        "                           legend=['train loss', 'trian acc', 'test acc'])\n",
        "    timer, num_batches = d2l.Timer(), len(train_iter)\n",
        "    for epoch in range(num_epochs):\n",
        "        \n",
        "        metric = d2l.Accumulator(3)\n",
        "        net.train()\n",
        "        for i, (X, y) in enumerate(train_iter):\n",
        "            timer.start()\n",
        "            optimizer.zero_grad()\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            y_hat = net(X)\n",
        "            l = loss(y_hat, y)\n",
        "            l.backward()\n",
        "            optimizer.step()\n",
        "            with torch.no_grad():\n",
        "                metric.add(l * X.shape[0], d2l.accuracy(y_hat, y), X.shape[0])\n",
        "            timer.stop()\n",
        "            train_l = metric[0] / metric[2]\n",
        "            train_acc = metric[1] / metric[2]\n",
        "            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
        "                animator.add(epoch + (i+1) / num_batches, (train_l, train_acc, None))\n",
        "        test_acc = d2l.evaluate_accuracy_gpu(net, test_iter)\n",
        "        animator.add(epoch + 1, (None, None, test_acc))                        \n",
        "    print(f'loss {train_l:.3f}, train acc {train_acc:.3f}',\n",
        "         f'test_acc {test_acc:.3f}')\n",
        "    print(f'{metric[2] *num_epochs / timer.sum():.1f} examples/sec',\n",
        "         f'on {str(device)}')\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "aa385899",
      "metadata": {
        "id": "aa385899"
      },
      "outputs": [],
      "source": [
        "#图片处理流水线 resize 224, 转为向量 归一化\n",
        "transform = transforms.Compose([transforms.Resize(224), \n",
        "                 transforms.ToTensor(), \n",
        "                transforms.RandomHorizontalFlip(),  # 随即反转\n",
        "                # transforms.RandomSizedCrop(224),\n",
        "                transforms.RandomCrop(96),\n",
        "                # transforms.ColorJitter(brightness=0.5, contrast=0.5, hue=0.5),\n",
        "                transforms.Normalize((0, 0, 0), (1, 1, 1))])\n",
        "train_dataset = datasets.ImageFolder(os.path.join('train', 'train'), transform=transform)\n",
        "test_dataset  = datasets.ImageFolder(os.path.join('train', 'test'), transform=transform)\n",
        "\n",
        "train_iter = torch.utils.data.DataLoader(train_dataset,batch_size=32, shuffle=True, num_workers = 2)\n",
        "test_iter = torch.utils.data.DataLoader(test_dataset,batch_size=32, shuffle=True, num_workers = 2)\n",
        "\n",
        "images = next(iter(test_iter))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# def imshow(img):\n",
        "#     # img = img / 2 + 0.5     # unnormalize\n",
        "#     npimg = img.numpy()\n",
        "#     plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "# imshow(test_iter)"
      ],
      "metadata": {
        "id": "rjKpeLIAaXyA"
      },
      "id": "rjKpeLIAaXyA",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9c35bac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9c35bac",
        "outputId": "344b8748-edb8-4ae8-ad63-b1989f0ea7a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trianing on cuda:0\n"
          ]
        }
      ],
      "source": [
        "lr, num_epochs, batch_size = 5, 10, 32\n",
        "\n",
        "\n",
        "train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "m4HHG2EvwAWZ"
      },
      "id": "m4HHG2EvwAWZ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "celltoolbar": "原始单元格格式",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "A树叶分类_colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}